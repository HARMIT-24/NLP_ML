{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PSO.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P6TUJCgCNsYs","executionInfo":{"status":"ok","timestamp":1620452163083,"user_tz":-330,"elapsed":4901,"user":{"displayName":"Harsh Mittal","photoUrl":"","userId":"12434610001146997162"}},"outputId":"bab8dca8-3406-4d8f-9378-1ea338afb7e2"},"source":["# Importing libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import SnowballStemmer\n","import string\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","stopwords = nltk.corpus.stopwords.words('english')\n","newStopWords = ['want','got','say','amp', 'thi', 'ain']\n","stopwords.extend(newStopWords)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xwqqzkbDOA9b"},"source":["def preprocess(text_string):\n","  text_string = text_string.translate(string.punctuation)\n","    ## Convert words to lower case and split them\n","  text_string = text_string.lower().split()\n","    ## Remove stop words\n","  text_string = [w for w in text_string if not w in stopwords and len(w) >= 3]\n","  text_string = \" \".join(text_string) \n","  space_pattern = '\\s+'\n","  giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n","      '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n","  mention_regex = '@\\w+\\W+'\n","  excliamation_regex = '!+'\n","  RT_regex = 'RT'\n","  parsed_text = re.sub(space_pattern, ' ', text_string)\n","  parsed_text = re.sub(excliamation_regex,'! ',parsed_text)\n","  parsed_text = re.sub(giant_url_regex, '', parsed_text)\n","  parsed_text = re.sub(mention_regex, '', parsed_text)\n","  parsed_text = re.sub(RT_regex,'', parsed_text)\n","  parsed_text = re.sub('(.)\\\\1{2,}', '\\\\1', parsed_text)\n","  parsed_text = re.sub('bitche', 'bitch',parsed_text)\n","  parsed_text.replace(\"#\", \"\")\n","  parsed_text = parsed_text.split()\n","  stemmer = SnowballStemmer('english')\n","  stemmed_words = [stemmer.stem(word) for word in parsed_text]\n","  parsed_text = \" \".join(stemmed_words)\n","  #parsed_text = parsed_text.code(\"utf-8\", errors='ignore')\n","  parsed_text = re.sub('[^a-zA-Z]',' ', parsed_text)\n","  return parsed_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nWtlOE6GNgKI"},"source":["# change dt for different models \n","from sklearn.ensemble import RandomForestClassifier\n","def sigmoid(x):\n","  return (1/(1+np.exp(-1*x)))  \n","dt = RandomForestClassifier(n_estimators = 100)\n","\n","def pso(X, Y, popu_size, maxItr=5):\n","  particles = []\n","  for i in range(popu_size):\n","      particles.append(np.random.choice([0, 1], size=1500))\n","  particles = np.array(particles,dtype=float)\n","  velocities = np.random.rand(popu_size,1500)\n","  itr = 0\n","  pbest = np.zeros((popu_size,1500))\n","  pbest_score = np.ones((popu_size,),dtype=float)*0\n","  gbest_score = 0\n","  gbest = np.zeros((1500,))\n","  while(itr < maxItr):\n","    # start = time()\n","    for i in range(popu_size):\n","      X_togive = np.multiply(X, particles[i])\n","      dt.fit(X_togive, Y)\n","      Xt = np.multiply(X_train, particles[i])\n","      score = dt.score(X_test,Y_test)\n","      if score > pbest_score[i]:\n","        pbest_score[i] = score\n","        pbest[i] = particles[i]\n","      if score > gbest_score:\n","        gbest_score = score\n","        gbest = pbest[i]\n","    for i in range(popu_size):\n","      velocities[i] = 0.4*velocities[i] + 2*np.random.rand()*(pbest[i]-particles[i]) +2*np.random.rand()*(gbest-particles[i])\n","      for kk in range(1500):\n","        if velocities[i][kk]>4.0:\n","          velocities[i][kk] =  4.0\n","        elif velocities[i][kk]<-4.0:\n","          velocities[i][kk] = -4.0\n","      velo_sig = sigmoid(velocities[i])\n","      for kk in range(97):\n","        particles[i][kk] = (np.random.randn()<velo_sig[kk])*1\n","    # end = time()\n","    print(\"Epochs:\",itr+1,\"Best Score:\",gbest_score)\n","    itr+=1\n","  return gbest"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"b5ORqJZaOE6C","executionInfo":{"status":"ok","timestamp":1620452164262,"user_tz":-330,"elapsed":6059,"user":{"displayName":"Harsh Mittal","photoUrl":"","userId":"12434610001146997162"}},"outputId":"70dc0e4c-a7b3-4782-ed26-e3dfd6731597"},"source":["df = pd.read_csv('https://raw.githubusercontent.com/MitHar24/dataset/main/New%20combined_Dataset.csv')\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>Tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>@BDUTT Shame on your hate news n fake news.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>@AP Pita can suck my ass! What a shit show of ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>@simonjames67 @Mr_John_Harvey_ @theJeremyVine ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>@GMB @SeanFletcherTV Oh wow.........what the h...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>@KallipolisState @talkRADIO @JuliaHB1 @spikedo...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Label                                              Tweet\n","0      1        @BDUTT Shame on your hate news n fake news.\n","1      1  @AP Pita can suck my ass! What a shit show of ...\n","2      0  @simonjames67 @Mr_John_Harvey_ @theJeremyVine ...\n","3      0  @GMB @SeanFletcherTV Oh wow.........what the h...\n","4      0  @KallipolisState @talkRADIO @JuliaHB1 @spikedo..."]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"D_30uXocOKVj","executionInfo":{"status":"ok","timestamp":1620452179833,"user_tz":-330,"elapsed":21617,"user":{"displayName":"Harsh Mittal","photoUrl":"","userId":"12434610001146997162"}},"outputId":"48287b0b-e31c-43d2-c49a-5c7655ac21fa"},"source":["df['processed'] = df['Tweet'].apply(lambda x: preprocess(x))\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>Tweet</th>\n","      <th>processed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>@BDUTT Shame on your hate news n fake news.</td>\n","      <td>shame hate news fake news</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>@AP Pita can suck my ass! What a shit show of ...</td>\n","      <td>pita suck ass  shit show organ put anim save</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>@simonjames67 @Mr_John_Harvey_ @theJeremyVine ...</td>\n","      <td>mr john harvey  waitros i m littl worri bank b...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>@GMB @SeanFletcherTV Oh wow.........what the h...</td>\n","      <td>seanfletchertv wow what hell know  wolv relega...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>@KallipolisState @talkRADIO @JuliaHB1 @spikedo...</td>\n","      <td>talkradio spikedonlin noth like outrag now  ma...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Label  ...                                          processed\n","0      1  ...                         shame hate news fake news \n","1      1  ...      pita suck ass  shit show organ put anim save \n","2      0  ...  mr john harvey  waitros i m littl worri bank b...\n","3      0  ...  seanfletchertv wow what hell know  wolv relega...\n","4      0  ...  talkradio spikedonlin noth like outrag now  ma...\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"CX0kpEaTOMq6"},"source":["corpus = []\n","for i in range(0, len(df)):\n","  review = df['processed'][i]\n","  # review = re.sub('[^a-zA-Z]',' ', df['processed'][i])\n","  corpus.append(review)\n","# Bag Of Words\n","from sklearn.feature_extraction.text import CountVectorizer\n","cv = CountVectorizer(max_features = 1500)\n","#creating matrix of features\n","X = cv.fit_transform(corpus).toarray()\n","Y = df.iloc[:,0].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_Z5PCNKOVPP"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aBCLpCg8hph_"},"source":["# Scaling the X parameters i.e. X_train and X_test\n","from sklearn.preprocessing import MinMaxScaler\n","sc_X = MinMaxScaler()\n","X_train = sc_X.fit_transform(X_train)\n","X_test = sc_X.fit_transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BMf1_dMXcFY_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620452184852,"user_tz":-330,"elapsed":754,"user":{"displayName":"Harsh Mittal","photoUrl":"","userId":"12434610001146997162"}},"outputId":"2a4492f7-4b97-411b-fdd8-0f14b3eb650a"},"source":["Y_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(55319,)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ba2Ypi5de3-p","executionInfo":{"status":"ok","timestamp":1620452305954,"user_tz":-330,"elapsed":871,"user":{"displayName":"Harsh Mittal","photoUrl":"","userId":"12434610001146997162"}},"outputId":"d990145b-9f72-4384-a1f6-1ce813abd475"},"source":["type(Y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"fqaHEPw6cFKN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620452184852,"user_tz":-330,"elapsed":747,"user":{"displayName":"Harsh Mittal","photoUrl":"","userId":"12434610001146997162"}},"outputId":"d49f0bc9-0201-4dff-c333-9c8dd04c556e"},"source":["X_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(55319, 1500)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjDSsOWSe_mx","executionInfo":{"status":"ok","timestamp":1620452322189,"user_tz":-330,"elapsed":949,"user":{"displayName":"Harsh Mittal","photoUrl":"","userId":"12434610001146997162"}},"outputId":"9cdeec77-2f19-4149-9ba7-ca32a0e35ca0"},"source":["type(X_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cZ3ZWSk6OX2C","executionInfo":{"status":"ok","timestamp":1620448254035,"user_tz":-330,"elapsed":5357372,"user":{"displayName":"Harsh Mittal","photoUrl":"","userId":"12434610001146997162"}},"outputId":"ba6f2595-87c4-4cd3-f143-7f3a24fe0627"},"source":["new_x = pso(X_train, Y_train,5,5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epochs: 1 Best Score: 0.774397181341065\n","Epochs: 2 Best Score: 0.774397181341065\n","Epochs: 3 Best Score: 0.774397181341065\n","Epochs: 4 Best Score: 0.774397181341065\n","Epochs: 5 Best Score: 0.7744705839174955\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vMGyoaiTS4ci"},"source":["X_togive = np.multiply(X_train,new_x)\n","dt.fit(X_togive, Y_train)\n","Y_pred = dt.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0jRZ_bvfazgV"},"source":["from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","f1 = f1_score(Y_test, Y_pred)\n","ps = precision_score(Y_test, Y_pred)\n","rs = recall_score(Y_test, Y_pred)\n","asc = accuracy_score(Y_test, Y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9hAzvQh3tlcs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620448449548,"user_tz":-330,"elapsed":195480,"user":{"displayName":"Harsh Mittal","photoUrl":"","userId":"12434610001146997162"}},"outputId":"757d158c-e755-4d14-877b-6f4dcc76a793"},"source":["print(f\"F1 Score {f1}\")\n","print(f\"Precesion Score {ps}\")\n","print(f\"Recall Score {rs}\")\n","print(f\"Accuracy Score {asc}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["F1 Score 0.7256399946387885\n","Precesion Score 0.8132385339475265\n","Recall Score 0.6550778414132451\n","Accuracy Score 0.7746173890703564\n"],"name":"stdout"}]}]}